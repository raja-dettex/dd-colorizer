{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raja-dettex/dd-colorizer/blob/main/Another_copy_of_colorization_pipeline_onnxruntime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/piddnad/DDColor.git"
      ],
      "metadata": {
        "id": "AOAlNmIY-cDx",
        "outputId": "8c73090e-688b-4a1f-b466-bf6ebef00574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DDColor'...\n",
            "remote: Enumerating objects: 260, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 260 (delta 61), reused 54 (delta 39), pack-reused 157 (from 1)\u001b[K\n",
            "Receiving objects: 100% (260/260), 15.21 MiB | 19.68 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qmH8jZQP_KIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **after first time you are done processed a set of images run only the second cell and last cell. **\n",
        "here is the flow\n",
        "for first time : run first cell -> run second cell -> upload images to 'images' folder(the 'images' folder is located in 'content' folder)  -> run rest of the cells one by one. (doing this will set your weights model and path and onnxruntime and ort_session to prepare the tensor)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "second time onwards: run second cell -> upload images to 'images' folder -> run the last cell\n",
        "## don't forget to download images from 'finalized' folder before running the next processing task"
      ],
      "metadata": {
        "id": "nnwFSQbs_UGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "weights_dir_path = '/content/DDColor/weights/'\n",
        "input_path = '/content/images'\n",
        "final_path = '/content/finalized/'\n",
        "os.makedirs(input_path, exist_ok=True)\n",
        "os.makedirs(weights_dir_path, exist_ok=True)\n",
        "os.makedirs(final_path, exist_ok=True)\n",
        "# cleanup after every batch task is complete\n",
        "for file in os.listdir(input_path):\n",
        "  os.remove(os.path.join(input_path, file))\n",
        "for file in os.listdir(final_path):\n",
        "  os.remove(os.path.join(final_path, file))"
      ],
      "metadata": {
        "id": "jWzpAKrM5OcC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime onnxsim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqdDOMH_uTJV",
        "outputId": "69275a5c-0232-4b4d-efa3-95809951be70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.13.2)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from onnxsim) (13.9.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (2.19.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxsim, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.18.0 onnxruntime-1.22.0 onnxsim-0.4.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZivauQS2UUd3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import onnxruntime as ort\n",
        "import tqdm\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "model_path = '/content/DDColor/weights/ddcolor-tiny-op12.onnx'    # python export.py --model_path pretrain/ddcolor_paper_tiny.pth --export_path weights/ddcolor-tiny-op12.onnx\n",
        "\n",
        "#Load some example image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://huggingface.co/piddnad/DDColor-models/resolve/main/ddcolor_paper_tiny.pth -P /content/DDColor/pretrain/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5ASWDvykvnkv",
        "outputId": "da5e5bda-e39a-49db-9be4-94dc010ad12c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-24 06:40:04--  https://huggingface.co/piddnad/DDColor-models/resolve/main/ddcolor_paper_tiny.pth\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.110, 3.166.152.105, 3.166.152.65, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/3b/44/3b4445552b072a12d344fe1e2de9fa43026713caab7ea3cd270c8423ba31fd0c/81dd643904f4664c3718513e3320ae3db0c567f0d3e18398606659adee7bfc17?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ddcolor_paper_tiny.pth%3B+filename%3D%22ddcolor_paper_tiny.pth%22%3B&Expires=1748072405&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODA3MjQwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8zYi80NC8zYjQ0NDU1NTJiMDcyYTEyZDM0NGZlMWUyZGU5ZmE0MzAyNjcxM2NhYWI3ZWEzY2QyNzBjODQyM2JhMzFmZDBjLzgxZGQ2NDM5MDRmNDY2NGMzNzE4NTEzZTMzMjBhZTNkYjBjNTY3ZjBkM2UxODM5ODYwNjY1OWFkZWU3YmZjMTc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=tceTsL7I3uXO2PhlsEwZJ38rswYceDGhJjeRaayWk0fXPX96jKCZNNXIJ2dpCmVG5z0pBW2R2A5NqJPzPT1hJjOGUguIlyHHl7d8KrHUuz4DS35ekigHN6teohsbiRmSXfYJpTks6TsCzoV2bDuG19C2Lmir6jEnFSvOAbV%7EgLMPGEI0yxj2ZceZSXShp3er1JjaDkWPV%7E41ntsBJBx7mkeAloQWJ7EnXNQHAMuTHZow8-EF6oJg6o4Tq6y0tj0DmprcfyQp2Ogqq0skiKVM-kMicT0oGyK0iioPlNTG6On8-tZhmBy0Lp3quCjTvNAbEb0eCI6jpc1AFG6UtpbRUw__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-05-24 06:40:05--  https://cdn-lfs.hf.co/repos/3b/44/3b4445552b072a12d344fe1e2de9fa43026713caab7ea3cd270c8423ba31fd0c/81dd643904f4664c3718513e3320ae3db0c567f0d3e18398606659adee7bfc17?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ddcolor_paper_tiny.pth%3B+filename%3D%22ddcolor_paper_tiny.pth%22%3B&Expires=1748072405&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODA3MjQwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8zYi80NC8zYjQ0NDU1NTJiMDcyYTEyZDM0NGZlMWUyZGU5ZmE0MzAyNjcxM2NhYWI3ZWEzY2QyNzBjODQyM2JhMzFmZDBjLzgxZGQ2NDM5MDRmNDY2NGMzNzE4NTEzZTMzMjBhZTNkYjBjNTY3ZjBkM2UxODM5ODYwNjY1OWFkZWU3YmZjMTc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=tceTsL7I3uXO2PhlsEwZJ38rswYceDGhJjeRaayWk0fXPX96jKCZNNXIJ2dpCmVG5z0pBW2R2A5NqJPzPT1hJjOGUguIlyHHl7d8KrHUuz4DS35ekigHN6teohsbiRmSXfYJpTks6TsCzoV2bDuG19C2Lmir6jEnFSvOAbV%7EgLMPGEI0yxj2ZceZSXShp3er1JjaDkWPV%7E41ntsBJBx7mkeAloQWJ7EnXNQHAMuTHZow8-EF6oJg6o4Tq6y0tj0DmprcfyQp2Ogqq0skiKVM-kMicT0oGyK0iioPlNTG6On8-tZhmBy0Lp3quCjTvNAbEb0eCI6jpc1AFG6UtpbRUw__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.173.166.89, 18.173.166.94, 18.173.166.43, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.173.166.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 220393145 (210M) [binary/octet-stream]\n",
            "Saving to: ‘/content/DDColor/pretrain/ddcolor_paper_tiny.pth’\n",
            "\n",
            "ddcolor_paper_tiny. 100%[===================>] 210.18M   165MB/s    in 1.3s    \n",
            "\n",
            "2025-05-24 06:40:06 (165 MB/s) - ‘/content/DDColor/pretrain/ddcolor_paper_tiny.pth’ saved [220393145/220393145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/DDColor/export.py --model_path /content/DDColor/pretrain/ddcolor_paper_tiny.pth --export_path /content/DDColor/weights/ddcolor-tiny-op12.onnx"
      ],
      "metadata": {
        "id": "CyZtzc4xvgif",
        "outputId": "136e2089-4417-4e6a-e00b-feea8ffb9a5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "ONNX file successfully created at /content/DDColor/weights/ddcolor-tiny-op12.onnx\n",
            "ONNX file at /content/DDColor/weights/ddcolor-tiny-op12.onnx verifed shapes and simplified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CPkSup7aUUd6",
        "outputId": "fcee530a-e559-4cd1-e590-e4dcd9aafb7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input name: input, shape: [1, 3, 512, 512]\n",
            "Output name: output, shape: [1, 2, 512, 512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'TensorrtExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tmp_ort_session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
        "\n",
        "# print the input,output names and shapes\n",
        "for i in range(len(tmp_ort_session.get_inputs())):\n",
        "    print(f\"Input name: {tmp_ort_session.get_inputs()[i].name}, shape: {tmp_ort_session.get_inputs()[i].shape}\")\n",
        "for i in range(len(tmp_ort_session.get_outputs())):\n",
        "    print(f\"Output name: {tmp_ort_session.get_outputs()[i].name}, shape: {tmp_ort_session.get_outputs()[i].shape}\")\n",
        "\n",
        "\n",
        "providers = [\n",
        "    # The TensorrtExecutionProvider is the fastest.\n",
        "    ('TensorrtExecutionProvider', {\n",
        "        'device_id': 0,\n",
        "        'trt_max_workspace_size': 4 * 1024 * 1024 * 1024,\n",
        "        'trt_fp16_enable': True,\n",
        "        'trt_engine_cache_enable': True,\n",
        "        'trt_engine_cache_path': './trt_engine_cache',\n",
        "        'trt_engine_cache_prefix': 'model',\n",
        "        'trt_dump_subgraphs': False,\n",
        "        'trt_timing_cache_enable': True,\n",
        "        'trt_timing_cache_path': './trt_engine_cache',\n",
        "        #'trt_builder_optimization_level': 3,\n",
        "    }),\n",
        "\n",
        "    # The CUDAExecutionProvider is slower than PyTorch,\n",
        "    # possibly due to performance issues with large matrix multiplication \"cossim = torch.bmm(feats1, feats2.permute(0,2,1))\"\n",
        "    # Reducing the top_k value when exporting to ONNX can decrease the matrix size.\n",
        "    ('CUDAExecutionProvider', {\n",
        "        'device_id': 0,\n",
        "        'gpu_mem_limit': 4 * 1024 * 1024 * 1024,\n",
        "    }),\n",
        "    ('CPUExecutionProvider',{\n",
        "    })\n",
        "]\n",
        "\n",
        "ort_session = ort.InferenceSession(model_path, providers=providers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7zWMfOVUUd7"
      },
      "source": [
        "## Prepare input tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MvUFqPANUUd9"
      },
      "outputs": [],
      "source": [
        "def process_single_image(ort_session, img_path, outfile_name):\n",
        "  input_size = 512\n",
        "  batch_size = 1\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "  height, width = img.shape[:2]\n",
        "  # print(self.width, self.height)\n",
        "  # if self.width * self.height < 100000:\n",
        "  #     self.input_size = 256\n",
        "\n",
        "  img = (img / 255.0).astype(np.float32)\n",
        "  orig_l = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:, :, :1]  # (h, w, 1)\n",
        "\n",
        "  # resize rgb image -> lab -> get grey -> rgb\n",
        "  img_resize = cv2.resize(img, (input_size, input_size))\n",
        "  img_l = cv2.cvtColor(img_resize, cv2.COLOR_BGR2Lab)[:, :, :1]\n",
        "  img_gray_lab = np.concatenate((img_l, np.zeros_like(img_l), np.zeros_like(img_l)), axis=-1)\n",
        "  img_gray_rgb = cv2.cvtColor(img_gray_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "  img_gray_rgb = img_gray_rgb.transpose((2, 0, 1)).astype(np.float32)\n",
        "  img_gray_rgb = np.expand_dims(img_gray_rgb, axis=0)\n",
        "\n",
        "  # Psuedo-batch the input images\n",
        "  img_gray_rgb = np.concatenate([img_gray_rgb for _ in range(batch_size)], axis=0)\n",
        "\n",
        "  inputs = {\n",
        "      ort_session.get_inputs()[0].name: img_gray_rgb,\n",
        "  }\n",
        "\n",
        "  # output_ab = self.model(tensor_gray_rgb).cpu()  # (1, 2, self.height, self.width)\n",
        "  output_ab = torch.from_numpy(ort_session.run(None, inputs)[0])\n",
        "\n",
        "  output_ab_resize = F.interpolate(output_ab, size=(height, width))[0].float().numpy().transpose(1, 2, 0)\n",
        "  output_lab = np.concatenate((orig_l, output_ab_resize), axis=-1)\n",
        "  output_rgb = cv2.cvtColor(output_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "  output_img = (output_rgb * 255.0).round().astype(np.uint8)\n",
        "  outfilepath = f'/content/finalized/{outfile_name}'\n",
        "  cv2.imwrite(outfilepath, output_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjO4vUfZUUd-"
      },
      "source": [
        "## Process output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here you can see using threadpoolexecutor you are able to achieve parallelism.\n",
        "here is the flow\n",
        "when u initiate a read it typically reads using fopen and fread which is implemented in c++ lib which gives the user-space-stream of bytes within a given fd space. so it typically does not hold the native python **GIL**. and therfore the the the raw bytes are converted to 3d numpy arr(height, width, channel) which is raw pixel data. here u might see a little bit of performance bottleneck.(only if a shared python bytecode). rest of the tasks like preparing input tensor and modifying the rgb values( i.e from grayscale to colored images) with onnxruntime. these libs are implemented in c++. so the cpython interpretor releases the **GIL** . here I have et 4 max_worker which is native os threads to process images. you can increase to 10 or 12 for a decent number of threads.\n",
        "to change max worker change the value of max_workers from 4 to changed value(i.e 8 or 10 or 12)."
      ],
      "metadata": {
        "id": "EFnSL9ptCrXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/images'\n",
        "image_files = os.listdir(input_dir)\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "output_dir = '/content/finalized'\n",
        "process_count = 0\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "  futures = [executor.submit(process_single_image, ort_session, os.path.join(input_dir, image_file), image_file) for image_file in image_files]\n",
        "  for future in futures:\n",
        "    result = future.result\n",
        "    if result:\n",
        "      process_count += 1\n",
        "print(f'finished processing {process_count} images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MASWSkrMw3Ab",
        "outputId": "35c2ad6a-bb7f-430a-b308-afb918c13935"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished processing 2 images\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ddcolor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}