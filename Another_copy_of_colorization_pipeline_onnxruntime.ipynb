{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raja-dettex/dd-colorizer/blob/main/Another_copy_of_colorization_pipeline_onnxruntime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/piddnad/DDColor.git"
      ],
      "metadata": {
        "id": "AOAlNmIY-cDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qmH8jZQP_KIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **after first time you are done processed a set of images run only the second cell and last cell. **\n",
        "here is the flow\n",
        "for first time : run first cell -> run second cell -> upload images to 'images' folder(the 'images' folder is located in 'content' folder)  -> run rest of the cells one by one. (doing this will set your weights model and path and onnxruntime and ort_session to prepare the tensor)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "second time onwards: run second cell -> upload images to 'images' folder -> run the last cell\n",
        "## don't forget to download images from 'finalized' folder before running the next processing task"
      ],
      "metadata": {
        "id": "nnwFSQbs_UGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "weights_dir_path = '/content/DDColor/weights/'\n",
        "input_path = '/content/images'\n",
        "final_path = '/content/finalized/'\n",
        "os.makedirs(input_path, exist_ok=True)\n",
        "os.makedirs(weights_dir_path, exist_ok=True)\n",
        "os.makedirs(final_path, exist_ok=True)\n",
        "# cleanup after every batch task is complete\n",
        "for file in os.listdir(input_path):\n",
        "  os.remove(os.path.join(input_path, file))\n",
        "for file in os.listdir(final_path):\n",
        "  os.remove(os.path.join(final_path, file))"
      ],
      "metadata": {
        "id": "jWzpAKrM5OcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime onnxsim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqdDOMH_uTJV",
        "outputId": "3767ecce-a813-4243-9ff1-436f5a37a5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.18.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.22.0)\n",
            "Requirement already satisfied: onnxsim in /usr/local/lib/python3.11/dist-packages (0.4.36)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.13.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from onnxsim) (13.9.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (2.19.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZivauQS2UUd3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import onnxruntime as ort\n",
        "import tqdm\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "model_path = '/content/DDColor/weights/ddcolor-tiny-op12.onnx'    # python export.py --model_path pretrain/ddcolor_paper_tiny.pth --export_path weights/ddcolor-tiny-op12.onnx\n",
        "\n",
        "#Load some example image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://huggingface.co/piddnad/DDColor-models/resolve/main/ddcolor_paper_tiny.pth -P /content/DDColor/pretrain/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5ASWDvykvnkv",
        "outputId": "c759d065-3887-48f0-964f-7245e19f73c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘/content/DDColor/pretrain/ddcolor_paper_tiny.pth’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/DDColor/export.py --model_path /content/DDColor/pretrain/ddcolor_paper_tiny.pth --export_path /content/DDColor/weights/ddcolor-tiny-op12.onnx"
      ],
      "metadata": {
        "id": "CyZtzc4xvgif",
        "outputId": "da78c6ac-6c5a-4eda-ccd9-8fbf80587b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "ONNX file successfully created at /content/DDColor/weights/ddcolor-tiny-op12.onnx\n",
            "ONNX file at /content/DDColor/weights/ddcolor-tiny-op12.onnx verifed shapes and simplified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPkSup7aUUd6",
        "outputId": "a18dcd29-4fe6-4e2f-f35e-7ba86c4fa947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input name: input, shape: [1, 3, 512, 512]\n",
            "Output name: output, shape: [1, 2, 512, 512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'TensorrtExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tmp_ort_session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
        "\n",
        "# print the input,output names and shapes\n",
        "for i in range(len(tmp_ort_session.get_inputs())):\n",
        "    print(f\"Input name: {tmp_ort_session.get_inputs()[i].name}, shape: {tmp_ort_session.get_inputs()[i].shape}\")\n",
        "for i in range(len(tmp_ort_session.get_outputs())):\n",
        "    print(f\"Output name: {tmp_ort_session.get_outputs()[i].name}, shape: {tmp_ort_session.get_outputs()[i].shape}\")\n",
        "\n",
        "\n",
        "providers = [\n",
        "    # The TensorrtExecutionProvider is the fastest.\n",
        "    ('TensorrtExecutionProvider', {\n",
        "        'device_id': 0,\n",
        "        'trt_max_workspace_size': 4 * 1024 * 1024 * 1024,\n",
        "        'trt_fp16_enable': True,\n",
        "        'trt_engine_cache_enable': True,\n",
        "        'trt_engine_cache_path': './trt_engine_cache',\n",
        "        'trt_engine_cache_prefix': 'model',\n",
        "        'trt_dump_subgraphs': False,\n",
        "        'trt_timing_cache_enable': True,\n",
        "        'trt_timing_cache_path': './trt_engine_cache',\n",
        "        #'trt_builder_optimization_level': 3,\n",
        "    }),\n",
        "\n",
        "    # The CUDAExecutionProvider is slower than PyTorch,\n",
        "    # possibly due to performance issues with large matrix multiplication \"cossim = torch.bmm(feats1, feats2.permute(0,2,1))\"\n",
        "    # Reducing the top_k value when exporting to ONNX can decrease the matrix size.\n",
        "    ('CUDAExecutionProvider', {\n",
        "        'device_id': 0,\n",
        "        'gpu_mem_limit': 4 * 1024 * 1024 * 1024,\n",
        "    }),\n",
        "    ('CPUExecutionProvider',{\n",
        "    })\n",
        "]\n",
        "\n",
        "ort_session = ort.InferenceSession(model_path, providers=providers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7zWMfOVUUd7"
      },
      "source": [
        "## Prepare input tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvUFqPANUUd9"
      },
      "outputs": [],
      "source": [
        "def process_single_image(ort_session, img_path, outfile_name):\n",
        "  input_size = 512\n",
        "  batch_size = 1\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "  height, width = img.shape[:2]\n",
        "  # print(self.width, self.height)\n",
        "  # if self.width * self.height < 100000:\n",
        "  #     self.input_size = 256\n",
        "\n",
        "  img = (img / 255.0).astype(np.float32)\n",
        "  orig_l = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:, :, :1]  # (h, w, 1)\n",
        "\n",
        "  # resize rgb image -> lab -> get grey -> rgb\n",
        "  img_resize = cv2.resize(img, (input_size, input_size))\n",
        "  img_l = cv2.cvtColor(img_resize, cv2.COLOR_BGR2Lab)[:, :, :1]\n",
        "  img_gray_lab = np.concatenate((img_l, np.zeros_like(img_l), np.zeros_like(img_l)), axis=-1)\n",
        "  img_gray_rgb = cv2.cvtColor(img_gray_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "  img_gray_rgb = img_gray_rgb.transpose((2, 0, 1)).astype(np.float32)\n",
        "  img_gray_rgb = np.expand_dims(img_gray_rgb, axis=0)\n",
        "\n",
        "  # Psuedo-batch the input images\n",
        "  img_gray_rgb = np.concatenate([img_gray_rgb for _ in range(batch_size)], axis=0)\n",
        "\n",
        "  inputs = {\n",
        "      ort_session.get_inputs()[0].name: img_gray_rgb,\n",
        "  }\n",
        "\n",
        "  # output_ab = self.model(tensor_gray_rgb).cpu()  # (1, 2, self.height, self.width)\n",
        "  output_ab = torch.from_numpy(ort_session.run(None, inputs)[0])\n",
        "\n",
        "  output_ab_resize = F.interpolate(output_ab, size=(height, width))[0].float().numpy().transpose(1, 2, 0)\n",
        "  output_lab = np.concatenate((orig_l, output_ab_resize), axis=-1)\n",
        "  output_rgb = cv2.cvtColor(output_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "  output_img = (output_rgb * 255.0).round().astype(np.uint8)\n",
        "  outfilepath = f'/content/finalized/{outfile_name}'\n",
        "  cv2.imwrite(outfilepath, output_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjO4vUfZUUd-"
      },
      "source": [
        "## Process output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/images'\n",
        "image_files = os.listdir(input_dir)\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "output_dir = '/content/finalized'\n",
        "process_count = 0\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "  futures = [executor.submit(process_single_image, ort_session, os.path.join(input_dir, image_file), image_file) for image_file in image_files]\n",
        "  for future in futures:\n",
        "    result = future.result\n",
        "    if result:\n",
        "      process_count += 1\n",
        "print(f'finished processing {process_count} images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MASWSkrMw3Ab",
        "outputId": "bf8287b2-5323-4e3f-b31b-69b8db2c7efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished processing 4 images\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ddcolor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}